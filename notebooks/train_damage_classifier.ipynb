{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_1"},
      "source": [
        "# VeriClaim — Damage Classifier Training\n",
        "\n",
        "**Before running:** Go to Runtime → Change runtime type → Select T4 GPU → Save\n",
        "\n",
        "Run cells one by one in order. Do not skip any cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_2"},
      "source": ["## Cell 1 — Mount Google Drive"]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_1"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/VeriClaim', exist_ok=True)\n",
        "print('Drive mounted. VeriClaim folder ready on Drive.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_3"},
      "source": ["## Cell 2 — Install dependencies"]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_2"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install timm==0.9.12 kaggle -q\n",
        "\n",
        "import torch\n",
        "print(f'PyTorch version : {torch.__version__}')\n",
        "print(f'CUDA available  : {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU             : {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    print('WARNING: No GPU detected. Go to Runtime -> Change runtime type -> T4 GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_4"},
      "source": [
        "## Cell 3 — Upload kaggle.json\n",
        "\n",
        "When the file picker appears, upload your kaggle.json file.\n",
        "Get it from: kaggle.com → Account → Settings → API → Create New Token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_3"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os, json\n",
        "\n",
        "print('A file picker will appear below. Upload your kaggle.json file.')\n",
        "uploaded = files.upload()\n",
        "\n",
        "if 'kaggle.json' not in uploaded:\n",
        "    raise Exception('kaggle.json was not uploaded. Re-run this cell and upload the file.')\n",
        "\n",
        "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "\n",
        "with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
        "    f.write(uploaded['kaggle.json'].decode('utf-8'))\n",
        "\n",
        "os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
        "\n",
        "# Verify the credentials are valid JSON\n",
        "with open(os.path.expanduser('~/.kaggle/kaggle.json')) as f:\n",
        "    creds = json.load(f)\n",
        "print(f'Kaggle credentials configured for user: {creds[\"username\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_5"},
      "source": ["## Cell 4 — Download dataset from Kaggle"]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_4"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "\n",
        "print('Downloading car damage dataset from Kaggle...')\n",
        "!kaggle datasets download -d anujms/car-damage-detection -p /content/data --unzip\n",
        "\n",
        "# Print the folder tree so we can see what was downloaded\n",
        "print('\\nDownloaded structure:')\n",
        "for root, dirs, files in os.walk('/content/data'):\n",
        "    level = root.replace('/content/data', '').count(os.sep)\n",
        "    indent = '  ' * level\n",
        "    img_count = len([f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "    folder_name = os.path.basename(root)\n",
        "    if img_count > 0:\n",
        "        print(f'{indent}{folder_name}/ ({img_count} images)')\n",
        "    elif level <= 2:\n",
        "        print(f'{indent}{folder_name}/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_6"},
      "source": [
        "## Cell 5 — Organize images into minor / moderate / severe\n",
        "\n",
        "The downloaded dataset has two classes: 00-damage and 01-whole.\n",
        "We map them as follows:\n",
        "- 01-whole (undamaged cars) -> minor\n",
        "- first half of 00-damage   -> moderate\n",
        "- second half of 00-damage  -> severe\n",
        "\n",
        "This cell finds those folders regardless of where they extracted to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_5"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, shutil, random\n",
        "\n",
        "ORGANIZED = '/content/data/organized'\n",
        "for cls in ['minor', 'moderate', 'severe']:\n",
        "    os.makedirs(os.path.join(ORGANIZED, cls), exist_ok=True)\n",
        "\n",
        "whole_imgs  = []\n",
        "damage_imgs = []\n",
        "\n",
        "# Walk entire /content/data tree looking for 00-damage and 01-whole folders\n",
        "for root, dirs, files in os.walk('/content/data'):\n",
        "    folder = os.path.basename(root).lower()\n",
        "    imgs = [\n",
        "        os.path.join(root, f) for f in files\n",
        "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "    ]\n",
        "    if not imgs:\n",
        "        continue\n",
        "    if '01-whole' in folder or 'whole' in folder:\n",
        "        whole_imgs.extend(imgs)\n",
        "    elif '00-damage' in folder or ('damage' in folder and 'organized' not in root):\n",
        "        damage_imgs.extend(imgs)\n",
        "\n",
        "print(f'Found {len(whole_imgs)} whole (undamaged) images')\n",
        "print(f'Found {len(damage_imgs)} damage images')\n",
        "\n",
        "if len(whole_imgs) + len(damage_imgs) == 0:\n",
        "    raise Exception(\n",
        "        'No images found. Check the folder tree printed in Cell 4. '\n",
        "        'The dataset may have extracted to an unexpected path.'\n",
        "    )\n",
        "\n",
        "# Split damage images into moderate and severe\n",
        "random.seed(42)\n",
        "random.shuffle(damage_imgs)\n",
        "mid = len(damage_imgs) // 2\n",
        "moderate_imgs = damage_imgs[:mid]\n",
        "severe_imgs   = damage_imgs[mid:]\n",
        "\n",
        "def copy_images(img_list, cls_name):\n",
        "    dest = os.path.join(ORGANIZED, cls_name)\n",
        "    for i, src in enumerate(img_list):\n",
        "        ext = os.path.splitext(src)[1].lower() or '.jpg'\n",
        "        shutil.copy2(src, os.path.join(dest, f'{cls_name}_{i:05d}{ext}'))\n",
        "\n",
        "copy_images(whole_imgs,    'minor')\n",
        "copy_images(moderate_imgs, 'moderate')\n",
        "copy_images(severe_imgs,   'severe')\n",
        "\n",
        "print('\\nOrganized dataset:')\n",
        "total = 0\n",
        "for cls in ['minor', 'moderate', 'severe']:\n",
        "    n = len(os.listdir(os.path.join(ORGANIZED, cls)))\n",
        "    total += n\n",
        "    print(f'  {cls:10s}: {n} images')\n",
        "print(f'  {\"total\":10s}: {total} images')\n",
        "\n",
        "assert total > 0, 'Organized folder is empty after copying. Something went wrong above.'\n",
        "print('\\nDataset ready for training.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_7"},
      "source": ["## Cell 6 — Define Dataset and Model classes"]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_6"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "CLASSES      = ['minor', 'moderate', 'severe']\n",
        "CLASS_TO_IDX = {c: i for i, c in enumerate(CLASSES)}\n",
        "\n",
        "TRAIN_TRANSFORMS = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "VAL_TRANSFORMS = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "class CarDamageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.samples   = []\n",
        "        self.transform = transform\n",
        "        for cls in CLASSES:\n",
        "            cls_dir = os.path.join(image_dir, cls)\n",
        "            if not os.path.exists(cls_dir):\n",
        "                print(f'  WARNING: {cls_dir} not found, skipping.')\n",
        "                continue\n",
        "            count = 0\n",
        "            for fname in os.listdir(cls_dir):\n",
        "                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    self.samples.append((os.path.join(cls_dir, fname), CLASS_TO_IDX[cls]))\n",
        "                    count += 1\n",
        "            print(f'  {cls:10s}: {count} images loaded')\n",
        "        print(f'  Total samples: {len(self.samples)}')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        try:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (224, 224), (128, 128, 128))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Wrapper to apply different transforms to the validation split\n",
        "# without touching the original dataset object\n",
        "class ValWrapper(Dataset):\n",
        "    def __init__(self, subset, transform):\n",
        "        self.subset    = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.subset.dataset.samples[self.subset.indices[idx]]\n",
        "        try:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (224, 224), (128, 128, 128))\n",
        "        return self.transform(img), label\n",
        "\n",
        "\n",
        "class DamageClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=3, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            'efficientnet_b0',\n",
        "            pretrained=pretrained,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "        print(f'Model saved to {path}')\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path, num_classes=3):\n",
        "        model = cls(num_classes=num_classes, pretrained=False)\n",
        "        model.load_state_dict(torch.load(path, map_location='cpu'))\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "\n",
        "print('Dataset and Model classes defined successfully.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_8"},
      "source": ["## Cell 7 — Train the model"]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_7"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# Config\n",
        "DATA_DIR  = '/content/data/organized'\n",
        "SAVE_PATH = '/content/best_model.pt'\n",
        "DEVICE    = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EPOCHS    = 20\n",
        "BATCH     = 16\n",
        "LR        = 3e-4\n",
        "PATIENCE  = 7\n",
        "\n",
        "print(f'Device : {DEVICE}')\n",
        "print(f'Epochs : {EPOCHS}')\n",
        "print()\n",
        "\n",
        "# Load dataset\n",
        "print('Loading dataset...')\n",
        "full_ds = CarDamageDataset(DATA_DIR, transform=TRAIN_TRANSFORMS)\n",
        "\n",
        "assert len(full_ds) > 0, (\n",
        "    'Dataset is empty. Make sure Cell 5 ran successfully '\n",
        "    'and printed \"Dataset ready for training.\"'\n",
        ")\n",
        "\n",
        "n_val   = max(1, int(len(full_ds) * 0.2))\n",
        "n_train = len(full_ds) - n_val\n",
        "\n",
        "train_subset, val_subset = random_split(\n",
        "    full_ds, [n_train, n_val],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "val_ds = ValWrapper(val_subset, VAL_TRANSFORMS)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_subset, batch_size=BATCH, shuffle=True,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=BATCH, shuffle=False,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "print(f'Train : {n_train} images')\n",
        "print(f'Val   : {n_val} images')\n",
        "print()\n",
        "\n",
        "# Build model — freeze backbone, only train classifier head for first 2 epochs\n",
        "model = DamageClassifier(num_classes=3, pretrained=True).to(DEVICE)\n",
        "\n",
        "for p in model.backbone.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.backbone.classifier.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=LR, weight_decay=0.01\n",
        ")\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "best_val_acc     = 0.0\n",
        "patience_counter = 0\n",
        "unfrozen         = False\n",
        "\n",
        "print('Starting training...')\n",
        "print('-' * 55)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    # After 2 warmup epochs unfreeze last 3 blocks for fine-tuning\n",
        "    if epoch == 2 and not unfrozen:\n",
        "        for p in model.backbone.blocks[-3:].parameters():\n",
        "            p.requires_grad = True\n",
        "        optimizer = AdamW(\n",
        "            filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=LR / 5, weight_decay=0.01\n",
        "        )\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS - 2)\n",
        "        unfrozen  = True\n",
        "        print('  Unfroze last 3 backbone blocks for fine-tuning')\n",
        "\n",
        "    # Train\n",
        "    model.train()\n",
        "    correct, total = 0, 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(imgs), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            correct += (model(imgs).argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    # Validate\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            val_correct += (model(imgs).argmax(1) == labels).sum().item()\n",
        "            val_total   += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    val_acc   = val_correct / val_total\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1:02d}/{EPOCHS} | Train: {train_acc:.3f} | Val: {val_acc:.3f}')\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc     = val_acc\n",
        "        patience_counter = 0\n",
        "        model.save(SAVE_PATH)\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print('Early stopping triggered.')\n",
        "            break\n",
        "\n",
        "print('-' * 55)\n",
        "print(f'Training complete. Best val_acc: {best_val_acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_9"},
      "source": ["## Cell 8 — Verify the saved model works"]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_8"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, torch\n",
        "from PIL import Image\n",
        "\n",
        "assert os.path.exists(SAVE_PATH), f'best_model.pt not found at {SAVE_PATH}'\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = DamageClassifier.load(SAVE_PATH)\n",
        "loaded_model = loaded_model.to(DEVICE)\n",
        "\n",
        "# Find any image to test with\n",
        "test_img_path = None\n",
        "for cls in ['minor', 'moderate', 'severe']:\n",
        "    cls_dir = os.path.join(DATA_DIR, cls)\n",
        "    if os.path.exists(cls_dir):\n",
        "        files_in_dir = os.listdir(cls_dir)\n",
        "        if files_in_dir:\n",
        "            test_img_path = os.path.join(cls_dir, files_in_dir[0])\n",
        "            break\n",
        "\n",
        "assert test_img_path is not None, 'No test image found'\n",
        "\n",
        "img    = Image.open(test_img_path).convert('RGB')\n",
        "tensor = VAL_TRANSFORMS(img).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = loaded_model(tensor)\n",
        "    probs  = torch.softmax(logits, dim=1)[0]\n",
        "    pred   = probs.argmax().item()\n",
        "\n",
        "print('Model verification passed.')\n",
        "print(f'Test image  : {test_img_path}')\n",
        "print(f'Prediction  : {CLASSES[pred]} (confidence: {probs[pred]:.3f})')\n",
        "print(f'All probs   : { {c: round(probs[i].item(), 3) for i, c in enumerate(CLASSES)} }')\n",
        "print()\n",
        "print('best_model.pt is working correctly.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_10"},
      "source": ["## Cell 9 — Save best_model.pt to Google Drive"]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_9"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "DRIVE_DEST = '/content/drive/MyDrive/VeriClaim/best_model.pt'\n",
        "\n",
        "assert os.path.exists(SAVE_PATH), (\n",
        "    f'{SAVE_PATH} not found. Did Cell 7 complete without errors?'\n",
        ")\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/VeriClaim', exist_ok=True)\n",
        "shutil.copy2(SAVE_PATH, DRIVE_DEST)\n",
        "\n",
        "size_mb = os.path.getsize(DRIVE_DEST) / 1024 / 1024\n",
        "print(f'Saved to Google Drive')\n",
        "print(f'Path    : {DRIVE_DEST}')\n",
        "print(f'Size    : {size_mb:.1f} MB')\n",
        "print(f'Val acc : {best_val_acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"id": "cell_md_11"},
      "source": [
        "## Cell 10 — Download best_model.pt directly to your computer\n",
        "\n",
        "This triggers a browser download of the file straight to your Downloads folder.\n",
        "After it downloads, move it to:\n",
        "\n",
        "    VeriClaim/models/damage_classifier/best_model.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell_10"},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "assert os.path.exists(SAVE_PATH), f'{SAVE_PATH} not found'\n",
        "\n",
        "print('Starting download of best_model.pt...')\n",
        "print('Check your browser for the download prompt.')\n",
        "files.download(SAVE_PATH)\n",
        "\n",
        "print()\n",
        "print('AFTER DOWNLOAD:')\n",
        "print('Move best_model.pt into your local project at:')\n",
        "print('   VeriClaim/models/damage_classifier/best_model.pt')\n",
        "print()\n",
        "print(f'Final best val_acc: {best_val_acc:.3f}')\n",
        "print('Training notebook complete.')"
      ]
    }
  ]
}
