{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MomPp5lX6YFJ"
      },
      "source": [
        "# VeriClaim — XGBoost Fraud Classifier Training\n",
        "\n",
        "No GPU needed. CPU runtime is fine for this notebook.\n",
        "\n",
        "Run cells one by one in order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sROuoflW6YIW"
      },
      "source": [
        "## Cell 1 — Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S584TrxM6YIc",
        "outputId": "2049a2a9-71eb-49ac-c50d-dc7249441a7a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost  : 3.2.0\n",
            "sklearn  : 1.6.1\n",
            "shap     : 0.50.0\n",
            "pandas   : 2.2.2\n",
            "Dependencies ready.\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost scikit-learn imbalanced-learn shap pandas joblib -q\n",
        "\n",
        "import xgboost, sklearn, shap, pandas\n",
        "print(f'xgboost  : {xgboost.__version__}')\n",
        "print(f'sklearn  : {sklearn.__version__}')\n",
        "print(f'shap     : {shap.__version__}')\n",
        "print(f'pandas   : {pandas.__version__}')\n",
        "print('Dependencies ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHmXbcsn6YIs"
      },
      "source": [
        "## Cell 2 — Upload kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "877yV6v-6YIs",
        "outputId": "716a04df-49dd-42d2-9298-6600ec0095fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your kaggle.json when the file picker appears.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-92f4e1e2-22e6-479a-b45c-ec48cbce6e07\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-92f4e1e2-22e6-479a-b45c-ec48cbce6e07\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Kaggle credentials configured for user: datascienceindee\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os, json\n",
        "\n",
        "print('Upload your kaggle.json when the file picker appears.')\n",
        "uploaded = files.upload()\n",
        "\n",
        "if 'kaggle.json' not in uploaded:\n",
        "    raise Exception('kaggle.json not uploaded. Re-run this cell.')\n",
        "\n",
        "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
        "    f.write(uploaded['kaggle.json'].decode('utf-8'))\n",
        "os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
        "\n",
        "with open(os.path.expanduser('~/.kaggle/kaggle.json')) as f:\n",
        "    creds = json.load(f)\n",
        "print(f'Kaggle credentials configured for user: {creds[\"username\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3OoywOi6YIt"
      },
      "source": [
        "## Cell 3 — Download insurance claims dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nRb8lD96YIu",
        "outputId": "497cea60-6047-48ae-ad5b-e15abc3fc6f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vehicle claim fraud dataset...\n",
            "Dataset URL: https://www.kaggle.com/datasets/shivamb/vehicle-claim-fraud-detection\n",
            "License(s): CC0-1.0\n",
            "Downloading vehicle-claim-fraud-detection.zip to /content/data\n",
            "  0% 0.00/348k [00:00<?, ?B/s]\n",
            "100% 348k/348k [00:00<00:00, 697MB/s]\n",
            "Found CSV: /content/data/fraud_oracle.csv\n",
            "\n",
            "Rows    : 15420\n",
            "Columns : ['Month', 'WeekOfMonth', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'FraudFound_P', 'PolicyNumber', 'RepNumber', 'Deductible', 'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'Year', 'BasePolicy']\n",
            "\n",
            "Fraud column check:\n",
            "  WARNING: fraud_reported column not found\n",
            "  Available columns: ['Month', 'WeekOfMonth', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'FraudFound_P', 'PolicyNumber', 'RepNumber', 'Deductible', 'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'Year', 'BasePolicy']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "\n",
        "print('Downloading vehicle claim fraud dataset...')\n",
        "!kaggle datasets download -d shivamb/vehicle-claim-fraud-detection -p /content/data --unzip\n",
        "\n",
        "# Find the CSV\n",
        "csv_path = None\n",
        "for root, dirs, files in os.walk('/content/data'):\n",
        "    for f in files:\n",
        "        if f.endswith('.csv'):\n",
        "            csv_path = os.path.join(root, f)\n",
        "            print(f'Found CSV: {csv_path}')\n",
        "\n",
        "if csv_path is None:\n",
        "    raise Exception('No CSV found after download. Check Kaggle credentials.')\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(csv_path)\n",
        "print(f'\\nRows    : {len(df)}')\n",
        "print(f'Columns : {df.columns.tolist()}')\n",
        "print(f'\\nFraud column check:')\n",
        "if 'fraud_reported' in df.columns:\n",
        "    print(f'  fraud_reported found')\n",
        "    print(f'  Fraud rate: {(df[\"fraud_reported\"] == \"Y\").mean():.2%}')\n",
        "else:\n",
        "    print('  WARNING: fraud_reported column not found')\n",
        "    print('  Available columns:', df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPnlmwr46YIv"
      },
      "source": [
        "## Cell 4 — Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQnMfPlq6YIv",
        "outputId": "33cc4f9e-12f5-437a-e0c0-301202dc9df2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering done.\n",
            "Columns now: ['Month', 'WeekOfMonth', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'FraudFound_P', 'PolicyNumber', 'RepNumber', 'Deductible', 'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'Year', 'BasePolicy']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "TIER1_CITIES = {\n",
        "    'mumbai', 'delhi', 'bangalore', 'bengaluru', 'hyderabad',\n",
        "    'chennai', 'kolkata', 'pune', 'ahmedabad'\n",
        "}\n",
        "TIER2_CITIES = {\n",
        "    'jaipur', 'lucknow', 'surat', 'nagpur', 'indore',\n",
        "    'bhopal', 'visakhapatnam', 'patna', 'vadodara'\n",
        "}\n",
        "FESTIVAL_MONTHS = {10, 11}\n",
        "\n",
        "\n",
        "def get_city_tier(city):\n",
        "    c = str(city).lower().strip()\n",
        "    if c in TIER1_CITIES: return 1\n",
        "    if c in TIER2_CITIES: return 2\n",
        "    return 3\n",
        "\n",
        "\n",
        "def get_hour_bin(hour):\n",
        "    try:\n",
        "        h = int(hour)\n",
        "    except (ValueError, TypeError):\n",
        "        return 2\n",
        "    if 2 <= h <= 4:  return 0\n",
        "    if h >= 22 or h <= 1: return 1\n",
        "    return 2\n",
        "\n",
        "\n",
        "def engineer_features(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    if 'incident_city' in df.columns:\n",
        "        df['city_tier'] = df['incident_city'].apply(get_city_tier)\n",
        "\n",
        "    if 'incident_date' in df.columns:\n",
        "        df['_idt'] = pd.to_datetime(df['incident_date'], errors='coerce')\n",
        "        df['incident_month']    = df['_idt'].dt.month\n",
        "        df['is_festival_season'] = df['incident_month'].isin(FESTIVAL_MONTHS).astype(int)\n",
        "        df.drop(columns=['_idt'], inplace=True)\n",
        "\n",
        "    if 'policy_bind_date' in df.columns and 'incident_date' in df.columns:\n",
        "        bind_dt     = pd.to_datetime(df['policy_bind_date'], errors='coerce')\n",
        "        incident_dt = pd.to_datetime(df['incident_date'],    errors='coerce')\n",
        "        df['policy_age_days'] = (incident_dt - bind_dt).dt.days.fillna(365)\n",
        "\n",
        "    if 'incident_hour_of_day' in df.columns:\n",
        "        df['incident_hour_bin'] = df['incident_hour_of_day'].apply(get_hour_bin)\n",
        "\n",
        "    if 'total_claim_amount' in df.columns and 'vehicle_claim' in df.columns:\n",
        "        df['claim_to_value_ratio'] = (\n",
        "            df['total_claim_amount'] / (df['vehicle_claim'] + 1)\n",
        "        ).clip(0, 10)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = engineer_features(df)\n",
        "print('Feature engineering done.')\n",
        "print(f'Columns now: {df.columns.tolist()}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this BEFORE Cell 5 — fixes the fraud column name\n",
        "\n",
        "print(\"All columns:\")\n",
        "for col in df.columns:\n",
        "    print(f\"  {col}\")\n",
        "\n",
        "fraud_col_candidates = [\n",
        "    'fraud_reported', 'fraud', 'FraudFound_P', 'FraudFound',\n",
        "    'fraud_found', 'is_fraud', 'Fraud', 'FRAUD', 'target', 'label'\n",
        "]\n",
        "\n",
        "found = None\n",
        "for candidate in fraud_col_candidates:\n",
        "    if candidate in df.columns:\n",
        "        found = candidate\n",
        "        print(f\"\\nFound fraud column: '{found}'\")\n",
        "        print(df[found].value_counts())\n",
        "        break\n",
        "\n",
        "if found is None:\n",
        "    print(\"\\nNot found automatically. Checking binary columns...\")\n",
        "    for col in df.columns:\n",
        "        if df[col].nunique() <= 3:\n",
        "            print(f\"  Possible: '{col}' — values: {df[col].unique()}\")\n",
        "else:\n",
        "    if found != 'fraud_reported':\n",
        "        df.rename(columns={found: 'fraud_reported'}, inplace=True)\n",
        "        print(f\"\\nRenamed '{found}' to 'fraud_reported'\")\n",
        "\n",
        "    vals = df['fraud_reported'].unique()\n",
        "    if set(vals).issubset({0, 1, '0', '1'}):\n",
        "        df['fraud_reported'] = df['fraud_reported'].map(\n",
        "            {1: 'Y', 0: 'N', '1': 'Y', '0': 'N'}\n",
        "        )\n",
        "        print(\"Converted 0/1 values to Y/N\")\n",
        "\n",
        "    print(f\"\\nFraud rate: {(df['fraud_reported'] == 'Y').mean():.2%}\")\n",
        "    print(\"Column ready. Now run Cell 5.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49G7sonR7Tz6",
        "outputId": "d021eef4-58d9-47ff-e1c0-ad5ba8ef242c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All columns:\n",
            "  Month\n",
            "  WeekOfMonth\n",
            "  DayOfWeek\n",
            "  Make\n",
            "  AccidentArea\n",
            "  DayOfWeekClaimed\n",
            "  MonthClaimed\n",
            "  WeekOfMonthClaimed\n",
            "  Sex\n",
            "  MaritalStatus\n",
            "  Age\n",
            "  Fault\n",
            "  PolicyType\n",
            "  VehicleCategory\n",
            "  VehiclePrice\n",
            "  FraudFound_P\n",
            "  PolicyNumber\n",
            "  RepNumber\n",
            "  Deductible\n",
            "  DriverRating\n",
            "  Days_Policy_Accident\n",
            "  Days_Policy_Claim\n",
            "  PastNumberOfClaims\n",
            "  AgeOfVehicle\n",
            "  AgeOfPolicyHolder\n",
            "  PoliceReportFiled\n",
            "  WitnessPresent\n",
            "  AgentType\n",
            "  NumberOfSuppliments\n",
            "  AddressChange_Claim\n",
            "  NumberOfCars\n",
            "  Year\n",
            "  BasePolicy\n",
            "\n",
            "Found fraud column: 'FraudFound_P'\n",
            "FraudFound_P\n",
            "0    14497\n",
            "1      923\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Renamed 'FraudFound_P' to 'fraud_reported'\n",
            "Converted 0/1 values to Y/N\n",
            "\n",
            "Fraud rate: 5.99%\n",
            "Column ready. Now run Cell 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX2CFR9l6YIx"
      },
      "source": [
        "## Cell 5 — Prepare features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8f_jXEu6YIx",
        "outputId": "73471195-21b0-473e-8b6b-a2a63adab5eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraud rate: 5.99%\n",
            "\n",
            "Encoding 25 categorical columns:\n",
            "  Month\n",
            "  DayOfWeek\n",
            "  Make\n",
            "  AccidentArea\n",
            "  DayOfWeekClaimed\n",
            "  MonthClaimed\n",
            "  Sex\n",
            "  MaritalStatus\n",
            "  Fault\n",
            "  PolicyType\n",
            "  VehicleCategory\n",
            "  VehiclePrice\n",
            "  Days_Policy_Accident\n",
            "  Days_Policy_Claim\n",
            "  PastNumberOfClaims\n",
            "  AgeOfVehicle\n",
            "  AgeOfPolicyHolder\n",
            "  PoliceReportFiled\n",
            "  WitnessPresent\n",
            "  AgentType\n",
            "  NumberOfSuppliments\n",
            "  AddressChange_Claim\n",
            "  NumberOfCars\n",
            "  BasePolicy\n",
            "\n",
            "Using 31 features:\n",
            "  Month\n",
            "  WeekOfMonth\n",
            "  DayOfWeek\n",
            "  Make\n",
            "  AccidentArea\n",
            "  DayOfWeekClaimed\n",
            "  MonthClaimed\n",
            "  WeekOfMonthClaimed\n",
            "  Sex\n",
            "  MaritalStatus\n",
            "  Age\n",
            "  Fault\n",
            "  PolicyType\n",
            "  VehicleCategory\n",
            "  VehiclePrice\n",
            "  RepNumber\n",
            "  Deductible\n",
            "  DriverRating\n",
            "  Days_Policy_Accident\n",
            "  Days_Policy_Claim\n",
            "  PastNumberOfClaims\n",
            "  AgeOfVehicle\n",
            "  AgeOfPolicyHolder\n",
            "  PoliceReportFiled\n",
            "  WitnessPresent\n",
            "  AgentType\n",
            "  NumberOfSuppliments\n",
            "  AddressChange_Claim\n",
            "  NumberOfCars\n",
            "  Year\n",
            "  BasePolicy\n",
            "\n",
            "X shape : (15420, 31)\n",
            "y shape : (15420,)\n",
            "Fraud   : 923 (5.99%)\n",
            "Ready for SMOTE.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# This dataset has different columns — map them correctly\n",
        "# fraud column is 'label' (0=no fraud, 1=fraud)\n",
        "print(f\"Fraud rate: {df['label'].mean():.2%}\")\n",
        "\n",
        "# Encode all object columns to numeric\n",
        "df_encoded = df.copy()\n",
        "le = LabelEncoder()\n",
        "\n",
        "object_cols = df_encoded.select_dtypes(include='object').columns.tolist()\n",
        "print(f\"\\nEncoding {len(object_cols)} categorical columns:\")\n",
        "for col in object_cols:\n",
        "    if col == 'fraud_reported':\n",
        "        continue\n",
        "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
        "    print(f\"  {col}\")\n",
        "\n",
        "# Feature columns — use everything except identifiers and target\n",
        "DROP_COLS = ['PolicyNumber', 'label', 'fraud_reported']\n",
        "FEATURE_COLS = [\n",
        "    c for c in df_encoded.columns\n",
        "    if c not in DROP_COLS\n",
        "    and df_encoded[c].dtype in ['int64', 'float64']\n",
        "]\n",
        "\n",
        "print(f\"\\nUsing {len(FEATURE_COLS)} features:\")\n",
        "for f in FEATURE_COLS:\n",
        "    print(f\"  {f}\")\n",
        "\n",
        "X = df_encoded[FEATURE_COLS].fillna(0)\n",
        "y = df['label']\n",
        "\n",
        "print(f\"\\nX shape : {X.shape}\")\n",
        "print(f\"y shape : {y.shape}\")\n",
        "print(f\"Fraud   : {y.sum()} ({y.mean():.2%})\")\n",
        "print(\"Ready for SMOTE.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this BEFORE Cell 6 — cleans up X so SMOTE works\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Drop any columns that are all NaN\n",
        "X = X.dropna(axis=1, how='all')\n",
        "\n",
        "# Convert everything to numeric, coerce strings to NaN then fill with 0\n",
        "X = X.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "# Drop any columns that are still object type\n",
        "obj_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "if obj_cols:\n",
        "    print(f'Dropping object columns: {obj_cols}')\n",
        "    X = X.drop(columns=obj_cols)\n",
        "\n",
        "# Update FEATURE_COLS to match what survived\n",
        "FEATURE_COLS = X.columns.tolist()\n",
        "\n",
        "print(f'X shape after cleanup: {X.shape}')\n",
        "print(f'Dtypes: {X.dtypes.value_counts().to_dict()}')\n",
        "print(f'Any NaN remaining: {X.isna().any().any()}')\n",
        "print(f'Features: {FEATURE_COLS}')\n",
        "print('Ready for SMOTE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAKIb3tS7g2U",
        "outputId": "6d34588f-720b-423c-e8a7-3bda4f5427ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape after cleanup: (15420, 31)\n",
            "Dtypes: {dtype('int64'): 31}\n",
            "Any NaN remaining: False\n",
            "Features: ['Month', 'WeekOfMonth', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'RepNumber', 'Deductible', 'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'Year', 'BasePolicy']\n",
            "Ready for SMOTE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"X columns:\", X.columns.tolist())\n",
        "print()\n",
        "\n",
        "# Check original df for the candidate columns\n",
        "print(\"Checking which candidate features exist in df:\")\n",
        "CANDIDATE_FEATURES = [\n",
        "    'months_as_customer', 'age', 'policy_annual_premium',\n",
        "    'umbrella_limit', 'capital-gains', 'capital-loss',\n",
        "    'incident_hour_of_day', 'number_of_vehicles_involved',\n",
        "    'bodily_injuries', 'witnesses',\n",
        "    'injury_claim', 'property_claim', 'vehicle_claim', 'total_claim_amount',\n",
        "    'city_tier', 'is_festival_season', 'policy_age_days',\n",
        "    'incident_hour_bin', 'claim_to_value_ratio', 'incident_month'\n",
        "]\n",
        "for col in CANDIDATE_FEATURES:\n",
        "    if col in df.columns:\n",
        "        print(f\"  EXISTS   {col} — dtype: {df[col].dtype} — sample: {df[col].iloc[0]}\")\n",
        "    else:\n",
        "        print(f\"  MISSING  {col}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Bc7zqs7x-R",
        "outputId": "cba530f8-0e0c-42b3-af11-f73fd555376b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (15420, 31)\n",
            "X columns: ['Month', 'WeekOfMonth', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'RepNumber', 'Deductible', 'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'Year', 'BasePolicy']\n",
            "\n",
            "Checking which candidate features exist in df:\n",
            "  MISSING  months_as_customer\n",
            "  MISSING  age\n",
            "  MISSING  policy_annual_premium\n",
            "  MISSING  umbrella_limit\n",
            "  MISSING  capital-gains\n",
            "  MISSING  capital-loss\n",
            "  MISSING  incident_hour_of_day\n",
            "  MISSING  number_of_vehicles_involved\n",
            "  MISSING  bodily_injuries\n",
            "  MISSING  witnesses\n",
            "  MISSING  injury_claim\n",
            "  MISSING  property_claim\n",
            "  MISSING  vehicle_claim\n",
            "  MISSING  total_claim_amount\n",
            "  MISSING  city_tier\n",
            "  MISSING  is_festival_season\n",
            "  MISSING  policy_age_days\n",
            "  MISSING  incident_hour_bin\n",
            "  MISSING  claim_to_value_ratio\n",
            "  MISSING  incident_month\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Actual columns in this dataset:\")\n",
        "for col in df.columns:\n",
        "    print(f\"  '{col}'  —  dtype: {df[col].dtype}  —  sample: {df[col].iloc[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06hWbTCT74Ua",
        "outputId": "cedb6898-863b-4cbd-f0da-daa2a9e6d653"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual columns in this dataset:\n",
            "  'Month'  —  dtype: object  —  sample: Dec\n",
            "  'WeekOfMonth'  —  dtype: int64  —  sample: 5\n",
            "  'DayOfWeek'  —  dtype: object  —  sample: Wednesday\n",
            "  'Make'  —  dtype: object  —  sample: Honda\n",
            "  'AccidentArea'  —  dtype: object  —  sample: Urban\n",
            "  'DayOfWeekClaimed'  —  dtype: object  —  sample: Tuesday\n",
            "  'MonthClaimed'  —  dtype: object  —  sample: Jan\n",
            "  'WeekOfMonthClaimed'  —  dtype: int64  —  sample: 1\n",
            "  'Sex'  —  dtype: object  —  sample: Female\n",
            "  'MaritalStatus'  —  dtype: object  —  sample: Single\n",
            "  'Age'  —  dtype: int64  —  sample: 21\n",
            "  'Fault'  —  dtype: object  —  sample: Policy Holder\n",
            "  'PolicyType'  —  dtype: object  —  sample: Sport - Liability\n",
            "  'VehicleCategory'  —  dtype: object  —  sample: Sport\n",
            "  'VehiclePrice'  —  dtype: object  —  sample: more than 69000\n",
            "  'fraud_reported'  —  dtype: object  —  sample: N\n",
            "  'PolicyNumber'  —  dtype: int64  —  sample: 1\n",
            "  'RepNumber'  —  dtype: int64  —  sample: 12\n",
            "  'Deductible'  —  dtype: int64  —  sample: 300\n",
            "  'DriverRating'  —  dtype: int64  —  sample: 1\n",
            "  'Days_Policy_Accident'  —  dtype: object  —  sample: more than 30\n",
            "  'Days_Policy_Claim'  —  dtype: object  —  sample: more than 30\n",
            "  'PastNumberOfClaims'  —  dtype: object  —  sample: none\n",
            "  'AgeOfVehicle'  —  dtype: object  —  sample: 3 years\n",
            "  'AgeOfPolicyHolder'  —  dtype: object  —  sample: 26 to 30\n",
            "  'PoliceReportFiled'  —  dtype: object  —  sample: No\n",
            "  'WitnessPresent'  —  dtype: object  —  sample: No\n",
            "  'AgentType'  —  dtype: object  —  sample: External\n",
            "  'NumberOfSuppliments'  —  dtype: object  —  sample: none\n",
            "  'AddressChange_Claim'  —  dtype: object  —  sample: 1 year\n",
            "  'NumberOfCars'  —  dtype: object  —  sample: 3 to 4\n",
            "  'Year'  —  dtype: int64  —  sample: 1994\n",
            "  'BasePolicy'  —  dtype: object  —  sample: Liability\n",
            "  'label'  —  dtype: int64  —  sample: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FosAgpnZ6YIy"
      },
      "source": [
        "## Cell 6 — Handle class imbalance with SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QacR0LKY6YIz",
        "outputId": "8e4da9ad-5bed-4f2b-b361-e6739e71c8a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before SMOTE — fraud: 923, non-fraud: 14497\n",
            "After SMOTE  — fraud: 14497, non-fraud: 14497\n",
            "New fraud rate: 50.00%\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(f'Before SMOTE — fraud: {y.sum()}, non-fraud: {(y==0).sum()}')\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "print(f'After SMOTE  — fraud: {y_res.sum()}, non-fraud: {(y_res==0).sum()}')\n",
        "print(f'New fraud rate: {y_res.mean():.2%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtlq4yzp6YIz"
      },
      "source": [
        "## Cell 7 — Train XGBoost with cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeI8OAsV6YI0",
        "outputId": "96f0ca62-8f81-43c9-a29b-347edfbe6ac3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 5-fold cross-validation on original data...\n",
            "CV AUC: 0.8464 +/- 0.0079\n",
            "\n",
            "Training final model on SMOTE-balanced data...\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric='auc',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Cross-validate on original (non-SMOTE) data for honest estimate\n",
        "print('Running 5-fold cross-validation on original data...')\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n",
        "print(f'CV AUC: {scores.mean():.4f} +/- {scores.std():.4f}')\n",
        "\n",
        "# Train final model on SMOTE-balanced data\n",
        "print('\\nTraining final model on SMOTE-balanced data...')\n",
        "model.fit(X_res, y_res)\n",
        "print('Training complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdj1FgAf6YI0"
      },
      "source": [
        "## Cell 8 — Save model as .pkl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz5lGFz26YI0",
        "outputId": "0e52558d-8a6c-4b2a-ed72-55e42ef06d23"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to  : /content/xgb_fraud_model.pkl\n",
            "Size      : 0.98 MB\n",
            "Features  : ['Month', 'WeekOfMonth', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'PolicyType', 'VehicleCategory', 'VehiclePrice', 'RepNumber', 'Deductible', 'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'Year', 'BasePolicy']\n"
          ]
        }
      ],
      "source": [
        "import joblib, os\n",
        "\n",
        "SAVE_PATH = '/content/xgb_fraud_model.pkl'\n",
        "\n",
        "# Save model AND feature column names together\n",
        "# The local predict.py needs both to run inference\n",
        "artifact = {\n",
        "    'model':        model,\n",
        "    'feature_cols': FEATURE_COLS\n",
        "}\n",
        "\n",
        "joblib.dump(artifact, SAVE_PATH)\n",
        "\n",
        "size_mb = os.path.getsize(SAVE_PATH) / 1024 / 1024\n",
        "print(f'Saved to  : {SAVE_PATH}')\n",
        "print(f'Size      : {size_mb:.2f} MB')\n",
        "print(f'Features  : {FEATURE_COLS}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-usO8unX6YI1"
      },
      "source": [
        "## Cell 9 — Verify the saved model works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa-KDMNC6YI1",
        "outputId": "915cc4da-3295-443e-822a-fb163db89677"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test prediction: fraud_probability = 0.0041\n",
            "Model verified. .pkl file is working correctly.\n"
          ]
        }
      ],
      "source": [
        "import joblib, pandas as pd\n",
        "\n",
        "loaded = joblib.load(SAVE_PATH)\n",
        "loaded_model = loaded['model']\n",
        "loaded_cols  = loaded['feature_cols']\n",
        "\n",
        "# Test with one row\n",
        "test_row = X.iloc[[0]][loaded_cols].fillna(0)\n",
        "prob = float(loaded_model.predict_proba(test_row)[0][1])\n",
        "\n",
        "print(f'Test prediction: fraud_probability = {prob:.4f}')\n",
        "assert 0.0 <= prob <= 1.0\n",
        "print('Model verified. .pkl file is working correctly.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2pWXSdW6YI2"
      },
      "source": [
        "## Cell 10 — Save to Google Drive and download to computer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "9S8fM38z6YI2",
        "outputId": "637fe6ce-df0a-4f80-ad97-513abde871ed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Saved to Google Drive: /content/drive/MyDrive/VeriClaim/xgb_fraud_model.pkl\n",
            "\n",
            "Starting download to your computer...\n",
            "Check your browser for the download prompt.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29544135-ec43-457a-a88b-765f6c2c42a8\", \"xgb_fraud_model.pkl\", 1024376)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AFTER DOWNLOAD:\n",
            "Place xgb_fraud_model.pkl at:\n",
            "  VeriClaim/models/fraud_classifier/xgb_fraud_model.pkl\n",
            "\n",
            "CV AUC achieved: 0.8464\n",
            "XGBoost training notebook complete.\n"
          ]
        }
      ],
      "source": [
        "import shutil, os\n",
        "from google.colab import drive, files\n",
        "\n",
        "# Save to Google Drive as backup\n",
        "drive.mount('/content/drive')\n",
        "os.makedirs('/content/drive/MyDrive/VeriClaim', exist_ok=True)\n",
        "drive_dest = '/content/drive/MyDrive/VeriClaim/xgb_fraud_model.pkl'\n",
        "shutil.copy2(SAVE_PATH, drive_dest)\n",
        "print(f'Saved to Google Drive: {drive_dest}')\n",
        "\n",
        "# Download directly to computer\n",
        "print('\\nStarting download to your computer...')\n",
        "print('Check your browser for the download prompt.')\n",
        "files.download(SAVE_PATH)\n",
        "\n",
        "print()\n",
        "print('AFTER DOWNLOAD:')\n",
        "print('Place xgb_fraud_model.pkl at:')\n",
        "print('  VeriClaim/models/fraud_classifier/xgb_fraud_model.pkl')\n",
        "print()\n",
        "print(f'CV AUC achieved: {scores.mean():.4f}')\n",
        "print('XGBoost training notebook complete.')"
      ]
    }
  ]
}